{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a466c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Sample data for df_table1 and df_table2\n",
    "df_table1 = {\n",
    "    'acb_no': [201, 202, 203, 204, 205, 206, 140],\n",
    "    'midnme': ['Smith', 'Johnson', 'Williams', 'Brown', 'Taylor', 'Clark', 'Chris'],\n",
    "    'dob': ['1980-01-01', '1976-05-10', '1987-09-15', '1988-03-24', '1980-07-14', '1990-04-18', '2000-01-28'],\n",
    "    'sex': ['M', 'F', 'M', 'F', 'M', 'F', 'M'],\n",
    "    'lst_name': ['Smith', 'Johnson', 'Williams', 'Brown', 'Taylor', 'Clark', 'Blue'],\n",
    "    'fst_name': ['John', 'Mary', 'Robert', 'Emily', 'Michael', 'Anna', 'Jorden'],\n",
    "    'snd_last': ['Doe', 'Martinez', 'Garcia', 'Miller', 'Davis', 'Rodriguez', 'Lewis'],\n",
    "    'dth_dte': ['2020-03-15', '2018-12-20', '2021-08-05', '2019-11-10', '2022-01-01', '2023-07-11', '2023-01-28'],\n",
    "    'uli': ['A123', 'B456', 'C789', '', 'D012', 'E345', 'F678'],\n",
    "    'bsurn': ['X123', 'Y456', '', 'Z789', 'W012', 'U345', 'T678'],\n",
    "    'ldgyr': ['2019-01-01', '2017-12-31', '2020-05-15', '2018-11-01', '2021-01-20', '2022-07-01', '2023-01-01'],\n",
    "    'region': [1, 2, 3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "df_table2 = {\n",
    "    'acbno1': [101, 107, 103, 104, 105, 106, 140],\n",
    "    'midnme1': ['Smith', 'Johnson', 'Williams', 'Brown', 'Taylor', 'Clark', 'Chris'],\n",
    "    'dob1': ['1980-01-01', '1975-05-10', '1992-09-15', '1988-03-25', '1985-07-14', '1990-04-18', '1999-01-28'],\n",
    "    'sex1': ['M', 'F', 'M', 'F', 'M', 'F', 'M'],\n",
    "    'lstnme1': ['Smith', 'Johnson', 'Williams', 'Brown', 'Taylor','Clark', 'Blue'],\n",
    "    'fstnme1': ['John', 'Mary', 'Robert', 'Emily', 'Michael', 'Anna', 'Jorden'],\n",
    "    'snd_last1': ['Doe', 'Martinez', 'Garcia', 'Miller', 'Davis', 'Rodriguez', 'Lewis'],\n",
    "    'dth_dte1': ['2020-03-15', '2018-12-20', '2021-08-05', '2019-11-10', '2022-01-01', '2023-07-11', '2023-01-28'],\n",
    "    'uli1': ['G123', 'B456', 'H789', 'I012', 'J345', 'K678', 'L901'],\n",
    "    'bsurn1': ['P123', 'Q456', 'R789', 'S012', 'T345', 'U678', 'V901'],\n",
    "    'ldgyr1': ['2018-01-01', '2016-12-31', '2019-05-15', '2017-11-01', '2020-01-20', '2021-07-01', '2022-01-01'],\n",
    "    'region1': [1, 2, 4, 4, 8, 1, 6]\n",
    "}\n",
    "\n",
    "# Convert dictionaries to DataFrames\n",
    "maligCCR1 = pd.DataFrame( df_table1 )\n",
    "maligCCR2 = pd.DataFrame( df_table2 )\n",
    "\n",
    "# Convert date columns to datetime\n",
    "maligCCR1['dob'] = pd.to_datetime(maligCCR1 ['dob'])\n",
    "maligCCR2['dob1'] = pd.to_datetime(maligCCR2['dob1'])\n",
    "\n",
    "maligCCR1['dth_dte'] = pd.to_datetime(df_table1['dth_dte'])\n",
    "maligCCR2['dth_dte1'] = pd.to_datetime(df_table2['dth_dte1'])\n",
    "\n",
    "maligCCR1['ldgyr'] = pd.to_datetime(df_table1['ldgyr'])\n",
    "maligCCR2['ldgyr1'] = pd.to_datetime(df_table2['ldgyr1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3bb49-afa9-4bd9-9701-a7188cedae7c",
   "metadata": {},
   "source": [
    "1. **First Method of Linking (link1a)**: The code creates a new table **`link1a`** by selecting all records from **`maligCCR1`** and **`maligCCR2`** where:\n",
    "    - The sex is the same in both tables.\n",
    "    - The **`acb_no`** in **`maligCCR2`** is not equal to **`acbno1`** in **`maligCCR1`**.\n",
    "    - The **`snd_last`** in **`maligCCR2`** is equal to **`snd_last1`** in **`maligCCR1`**.\n",
    "    - The date of birth (**`dob`**) in **`maligCCR2`** matches **`dob1`** in **`maligCCR1`** in one of several specific ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "585dac75-be77-4c3c-b3a7-b12ae8e24bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create link1a by selecting records that meet the specified conditions\n",
    "link1a = pd.merge(maligCCR1, maligCCR2, left_on='sex', right_on='sex1', suffixes=('', '1'))\n",
    "link1a = link1a[(link1a['acb_no'] != link1a['acbno1']) &\n",
    "                (link1a['snd_last'] == link1a['snd_last1']) &\n",
    "                ((link1a['dob'] == link1a['dob1']))]\n",
    "def method_1_link (row):\n",
    "    condition1 = row['acb_no'] != row['acbno1']\n",
    "    condition2 = row['snd_last'] == row['snd_last1']\n",
    "    conditon3 = row['dob'] == row['dob1']\n",
    "\n",
    "    if condition1 & condition2 & condition3\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9f926-f3f5-4ea7-a81d-e1af01100897",
   "metadata": {},
   "source": [
    "/**LINK1A: ALL LINKS FOR CCR YEARS USING 2ND MTHD OF LINKING**************/\n",
    "\n",
    "1. **Second Method of Linking (link1b)**: The code creates another table **`link1b`** by selecting all records from **`maligCCR1`** and **`maligCCR2`** where:\n",
    "    - The sex is the same in both tables.\n",
    "    - The **`acb_no`** in **`maligCCR2`** is not equal to **`acbno1`** in **`maligCCR1`**.\n",
    "    - The **`lst_name`** in **`maligCCR2`** is equal to **`lstnme1`** in **`maligCCR1`**.\n",
    "    - The first name in **`maligCCR2`** matches either the first name or middle name in **`maligCCR1`**.\n",
    "    - The death date (**`dth_dte`**) in **`maligCCR2`** is equal to **`dth_dte1`** in **`maligCCR1`**.\n",
    "    - The absolute difference between the year of birth in **`maligCCR2`** and **`maligCCR1`** is less than or equal to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "135e2564-d239-453c-949d-2c4c2875c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acb_no    midnme        dob sex  lst_name fst_name   snd_last    dth_dte  \\\n",
      "0     201     Smith 1980-01-01   M     Smith     John        Doe 2020-03-15   \n",
      "1     203  Williams 1987-09-15   M  Williams   Robert     Garcia 2021-08-05   \n",
      "2     205    Taylor 1980-07-14   M    Taylor  Michael      Davis 2022-01-01   \n",
      "3     202   Johnson 1976-05-10   F   Johnson     Mary   Martinez 2018-12-20   \n",
      "4     204     Brown 1988-03-24   F     Brown    Emily     Miller 2019-11-10   \n",
      "5     206     Clark 1990-04-18   F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "\n",
      "    uli bsurn  ...       dob1  sex1   lstnme1  fstnme1  snd_last1   dth_dte1  \\\n",
      "0  A123  X123  ... 1980-01-01     M     Smith     John        Doe 2020-03-15   \n",
      "1  C789        ... 1992-09-15     M  Williams   Robert     Garcia 2021-08-05   \n",
      "2  D012  W012  ... 1985-07-14     M    Taylor  Michael      Davis 2022-01-01   \n",
      "3  B456  Y456  ... 1975-05-10     F   Johnson     Mary   Martinez 2018-12-20   \n",
      "4        Z789  ... 1988-03-25     F     Brown    Emily     Miller 2019-11-10   \n",
      "5  E345  U345  ... 1990-04-18     F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "\n",
      "   uli1 bsurn1     ldgyr1 region1  \n",
      "0  G123   P123 2018-01-01       1  \n",
      "1  H789   R789 2019-05-15       4  \n",
      "2  J345   T345 2020-01-20       8  \n",
      "3  B456   Q456 2016-12-31       2  \n",
      "4  I012   S012 2017-11-01       4  \n",
      "5  K678   U678 2021-07-01       1  \n",
      "\n",
      "[6 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "link1b = pd.merge(maligCCR1, maligCCR2, left_on='sex', right_on='sex1', suffixes=('', '1'))\n",
    "link1b = link1b[(link1b['acb_no'] != link1b['acbno1']) &\n",
    "                (link1b['lst_name'] == link1b['lstnme1']) &\n",
    "                ((link1b['fst_name'] == link1b['fstnme1']) | (link1b['fst_name'] == link1b['midnme1'])) &\n",
    "                (link1b['dth_dte'] == link1b['dth_dte1']) &\n",
    "                (abs((link1b['dob'] - link1b['dob1']).dt.days / 365.25) <= 10)]\n",
    "\n",
    "# Optional: Reset index if needed\n",
    "link1b.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now link1b contains the filtered records\n",
    "print(link1b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d086593-9a3a-480b-aad8-37b42d61a080",
   "metadata": {},
   "source": [
    "### 2.Flagging Matches in link1b:\n",
    "- The code then adds a **`matflag`** variable to **`link1b`** based on the degree of match between the dates of birth in **`table1`**  and **`table2`**\n",
    "- **Calculate the Difference in Birth Years:**\n",
    "    - Loop through each record in `link1b`.\n",
    "    - Calculate the absolute difference between the year part of `dob` and `dob1`.\n",
    "    - Store this difference in a new column `dob_year_diff` in `link1b`.\n",
    "- **Add Match Flag (matflag):**\n",
    "    - Loop through each record in `link1b`.\n",
    "    - Set `matflag` to 'Exact Match' if `dob_year_diff` is 0.\n",
    "    - Set `matflag` to 'Close Match' if `dob_year_diff` is greater than 0 and less than or equal to 1.\n",
    "    - Set `matflag` to 'Partial Match' if `dob_year_diff` is greater than 1 and less than or equal to 5.\n",
    "    - Store the `matflag` in `link1b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9fc34a35-480e-460e-aeec-deb6747c7780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exact Matches:\n",
      "\n",
      "Close Matches:\n",
      "Mary Johnson - Mary Johnson\n",
      "\n",
      "Partial Matches:\n",
      "Robert Williams - Robert Williams\n",
      "Michael Taylor - Michael Taylor\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dob_year_diff and matflag columns for link1a\n",
    "link1a['dob_year_diff'] = pd.NA\n",
    "link1a['matflag'] = pd.NA\n",
    "\n",
    "# Calculate the difference in birth years between dob and dob1\n",
    "link1b['dob_year_diff'] = abs(pd.to_datetime(link1b['dob']).dt.year - pd.to_datetime(link1b['dob1']).dt.year)\n",
    "\n",
    "# Add matflag based on the difference in birth years\n",
    "link1b['matflag'] = 'Exact Match'\n",
    "link1b.loc[(link1b['dob_year_diff'] <= 1) & (link1b['dob_year_diff'] > 0), 'matflag'] = 'Close Match'\n",
    "link1b.loc[(link1b['dob_year_diff'] <= 5) & (link1b['dob_year_diff'] > 1), 'matflag'] = 'Partial Match'\n",
    "\n",
    "# Print the updated link1b table\n",
    "\n",
    "\n",
    "\n",
    "# Identify and print names of individuals with Close Match, Partial Match, or Exact Match\n",
    "exact_matches = Links1[Links1['matflag'] == 'Exact Match']\n",
    "close_matches = Links1[Links1['matflag'] == 'Close Match']\n",
    "partial_matches = Links1[Links1['matflag'] == 'Partial Match']\n",
    "\n",
    "\n",
    "print(\"\\nExact Matches:\")\n",
    "for _, row in exact_matches.iterrows():\n",
    "    print(f\"{row['fst_name']} {row['lst_name']} - {row['fstnme1']} {row['lstnme1']}\")\n",
    "\n",
    "print(\"\\nClose Matches:\")\n",
    "for _, row in close_matches.iterrows():\n",
    "    print(f\"{row['fst_name']} {row['lst_name']} - {row['fstnme1']} {row['lstnme1']}\")\n",
    "\n",
    "print(\"\\nPartial Matches:\")\n",
    "for _, row in partial_matches.iterrows():\n",
    "    print(f\"{row['fst_name']} {row['lst_name']} - {row['fstnme1']} {row['lstnme1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f53ba9-1a5e-4c72-b5c5-e63d5e30dd2b",
   "metadata": {},
   "source": [
    "### 3.Sorting and Depulication: \n",
    "- The code sorts **`Links1`** by **`acb_no`** and **`acb_no1`** and removes any duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f699dfa8-d19c-450f-b666-2b1c578f4c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acb_no    midnme        dob sex  lst_name fst_name   snd_last    dth_dte  \\\n",
      "0     201     Smith 1980-01-01   M     Smith     John        Doe 2020-03-15   \n",
      "5     202   Johnson 1976-05-10   F   Johnson     Mary   Martinez 2018-12-20   \n",
      "3     203  Williams 1987-09-15   M  Williams   Robert     Garcia 2021-08-05   \n",
      "6     204     Brown 1988-03-24   F     Brown    Emily     Miller 2019-11-10   \n",
      "4     205    Taylor 1980-07-14   M    Taylor  Michael      Davis 2022-01-01   \n",
      "1     206     Clark 1990-04-18   F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "\n",
      "    uli bsurn  ...   lstnme1  fstnme1  snd_last1   dth_dte1  uli1 bsurn1  \\\n",
      "0  A123  X123  ...     Smith     John        Doe 2020-03-15  G123   P123   \n",
      "5  B456  Y456  ...   Johnson     Mary   Martinez 2018-12-20  B456   Q456   \n",
      "3  C789        ...  Williams   Robert     Garcia 2021-08-05  H789   R789   \n",
      "6        Z789  ...     Brown    Emily     Miller 2019-11-10  I012   S012   \n",
      "4  D012  W012  ...    Taylor  Michael      Davis 2022-01-01  J345   T345   \n",
      "1  E345  U345  ...     Clark     Anna  Rodriguez 2023-07-11  K678   U678   \n",
      "\n",
      "      ldgyr1 region1 dob_year_diff        matflag  \n",
      "0 2018-01-01       1           NaN            NaN  \n",
      "5 2016-12-31       2             1    Close Match  \n",
      "3 2019-05-15       4             5  Partial Match  \n",
      "6 2017-11-01       4             0    Exact Match  \n",
      "4 2020-01-20       8             5  Partial Match  \n",
      "1 2021-07-01       1           NaN            NaN  \n",
      "\n",
      "[6 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combining the Links (Links1)\n",
    "Links1= pd.concat([link1a, link1b.astype(link1a.dtypes)], ignore_index=True)\n",
    "# Sorting and Deduplication\n",
    "Links1.sort_values(by=['acb_no', 'acbno1'], inplace=True)\n",
    "\n",
    "# Drop rows where matflag is 'Exact Match'\n",
    "Links1.drop_duplicates(subset=['acb_no', 'acbno1'], keep='first', +)\n",
    "print(Links1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b3692-f9d8-41af-a3eb-20109b60625a",
   "metadata": {},
   "source": [
    "## Create a new dataset called **`links1_step1`** based on the existing **`links1`** dataset.\n",
    "   1. **Define an attribute for the **`fileno1`** and **`fileno2`** variables with a length of 7 characters.**\n",
    "    - Determine which **`acb_no`** and **`acbno1`** should be used as **`fileno1`** and **`fileno2`**:\n",
    "        - If **`acb_no`** is greater than **`acbno1`**, set **`fileno1`** to **`acbno1`** and **`fileno2`** to **`acb_no`**.\n",
    "        - Otherwise, set **`fileno1`** to **`acb_no`** and **`fileno2`** to **`acbno1`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2aca6779-cc21-47bb-9f0d-592121c912b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acb_no    midnme        dob sex  lst_name fst_name   snd_last    dth_dte  \\\n",
      "0     201     Smith 1980-01-01   M     Smith     John        Doe 2020-03-15   \n",
      "5     202   Johnson 1976-05-10   F   Johnson     Mary   Martinez 2018-12-20   \n",
      "3     203  Williams 1987-09-15   M  Williams   Robert     Garcia 2021-08-05   \n",
      "4     205    Taylor 1980-07-14   M    Taylor  Michael      Davis 2022-01-01   \n",
      "1     206     Clark 1990-04-18   F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "\n",
      "    uli bsurn  ...  snd_last1   dth_dte1  uli1 bsurn1     ldgyr1 region1  \\\n",
      "0  A123  X123  ...        Doe 2020-03-15  G123   P123 2018-01-01       1   \n",
      "5  B456  Y456  ...   Martinez 2018-12-20  B456   Q456 2016-12-31       2   \n",
      "3  C789        ...     Garcia 2021-08-05  H789   R789 2019-05-15       4   \n",
      "4  D012  W012  ...      Davis 2022-01-01  J345   T345 2020-01-20       8   \n",
      "1  E345  U345  ...  Rodriguez 2023-07-11  K678   U678 2021-07-01       1   \n",
      "\n",
      "  dob_year_diff        matflag  fileno1  fileno2  \n",
      "0           NaN            NaN  0000101  0000201  \n",
      "5             1    Close Match  0000107  0000202  \n",
      "3             5  Partial Match  0000103  0000203  \n",
      "4             5  Partial Match  0000105  0000205  \n",
      "1           NaN            NaN  0000106  0000206  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15036\\1445537060.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Links1['fileno1'] = fileno1\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15036\\1445537060.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Links1['fileno2'] = fileno2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize fileno1 and fileno2 columns\n",
    "fileno1 = []\n",
    "fileno2 = []\n",
    "\n",
    "# Determine fileno1 and fileno2 based on acb_no and acbno\n",
    "for index, row in Links1.iterrows():\n",
    "    if row['acb_no'] > row['acbno1']:\n",
    "        fileno1.append(str(row['acbno1']).zfill(7))\n",
    "        fileno2.append(str(row['acb_no']).zfill(7))\n",
    "    else:\n",
    "        fileno1.append(str(row['acb_no']).zfill(7))\n",
    "        fileno2.append(str(row['acbno1']).zfill(7))\n",
    "\n",
    "# Add fileno1 and fileno2 to the DataFrame\n",
    "Links1['fileno1'] = fileno1\n",
    "Links1['fileno2'] = fileno2\n",
    "\n",
    "# Create links1_step1 DataFrame\n",
    "links1_step1 = Links1.copy()\n",
    "\n",
    "print(links1_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496628e-1bc9-4f18-a16d-26d7c3d7bfdb",
   "metadata": {},
   "source": [
    "### Handling Cases Using mthd1 for Linking:\n",
    "1. **Conditions for Linking (Method 1 - `mthd1`):**\r\n",
    "    - The following conditions must be met for a record to be included in the new variable **`pflag`**:\r\n",
    "        - If **`dob`** in one dataset (**`maligCCR1`**) is equal to **`dob1`** in another dataset (**`maligCCR2`**).\r\n",
    "        - Or, if specific date-related criteria are met:\r\n",
    "            - The year part of **`dob1`** minus 1900 equals the day part of **`dob`**, and the day part of **`dob1`** equals the year part of **`dob`** minus 1900, and the month part of **`dob1`** equals the month part of **`dob`**.\r\n",
    "            - Or, the month part of **`dob1`** equals the year part of **`dob`** minus 1900, and the year part of **`dob1`** minus 1900 equals the month part of **`dob`**, and the day part of **`dob1`** equals the day part of **`dob`**.\r\n",
    "            - Or, the year part of **`dob1`** equals the year part of **`dob`**, and the day part of **`dob1`** equals the month part of **`dob`**, and the month part of **`dob1`** equals the day part of **`dob`**.\r\n",
    "        - If **`uli`** in both datasets is not empty and not equal, and **`fst_name`** in one dataset is not equal to **`fstnme1`** in the other dataset.\r\n",
    "        - Or, if **`bsurn1`** in one dataset is not equal to **`bsurn`** in the other dataset, and neither **`bsurn1`** nor **`bsurn`** is empty.\r\n",
    "    - If any of these conditions are met, set **`pflag`** to 1; otherwise, set 2t to 0.\r\n",
    "3. **Result:**\r\n",
    "    - The resulting **`pflag`** variable will indicate whether a record meets the specified linking conditions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "48dc14bd-6765-4232-91f1-674362a9c535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acb_no    midnme        dob sex  lst_name fst_name   snd_last    dth_dte  \\\n",
      "0     201     Smith 1980-01-01   M     Smith     John        Doe 2020-03-15   \n",
      "5     202   Johnson 1976-05-10   F   Johnson     Mary   Martinez 2018-12-20   \n",
      "3     203  Williams 1987-09-15   M  Williams   Robert     Garcia 2021-08-05   \n",
      "4     205    Taylor 1980-07-14   M    Taylor  Michael      Davis 2022-01-01   \n",
      "1     206     Clark 1990-04-18   F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "\n",
      "    uli bsurn  ...   dth_dte1  uli1  bsurn1     ldgyr1 region1 dob_year_diff  \\\n",
      "0  A123  X123  ... 2020-03-15  G123    P123 2018-01-01       1           NaN   \n",
      "5  B456  Y456  ... 2018-12-20  B456    Q456 2016-12-31       2             1   \n",
      "3  C789        ... 2021-08-05  H789    R789 2019-05-15       4             5   \n",
      "4  D012  W012  ... 2022-01-01  J345    T345 2020-01-20       8             5   \n",
      "1  E345  U345  ... 2023-07-11  K678    U678 2021-07-01       1           NaN   \n",
      "\n",
      "         matflag  fileno1  fileno2 pflag  \n",
      "0            NaN  0000101  0000201     1  \n",
      "5    Close Match  0000107  0000202     1  \n",
      "3  Partial Match  0000103  0000203     2  \n",
      "4  Partial Match  0000105  0000205     1  \n",
      "1            NaN  0000106  0000206     1  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize pflag\n",
    "links1_step1['pflag'] = 0\n",
    "\n",
    "\n",
    "# Define a function to check the conditions\n",
    "def check_conditions(row):\n",
    "    # Initial conditions for method one\n",
    "    condition1 = row['dob'] == row['dob1']\n",
    "    condition2 = (row['dob1'].year - 1900 == row['dob'].day) and (row['dob1'].day == row['dob'].year - 1900) and (row['dob1'].month == row['dob'].month)\n",
    "    condition3 = (row['dob1'].month == row['dob'].year - 1900) and (row['dob1'].year - 1900 == row['dob'].month) and (row['dob1'].day == row['dob'].day)\n",
    "    condition4 = (row['dob1'].year == row['dob'].year) and (row['dob1'].day == row['dob'].month) and (row['dob1'].month == row['dob'].day)\n",
    "    condition5 = row['uli'] and row['uli1'] and row['uli'] != row['uli1'] and row['fst_name'] != row['fstnme1']\n",
    "    condition6 = row['bsurn'] and row['bsurn1'] and row['bsurn'] != row['bsurn1']\n",
    "\n",
    "    # Additional conditions for pflag = 2\n",
    "    condition7 = row['uli'] and row['uli1'] and row['uli'] != row['uli1']\n",
    "    condition8 = row['bsurn'] and row['bsurn1'] and row['bsurn'] != row['bsurn']\n",
    "\n",
    "     # Additional conditions for pflag = 3\n",
    "    condition9 = abs((row['dth_dte'] - row['dth_dte1']).days) > 60\n",
    "    condition10 = row['ldgyr'] > row['dth_dte1']\n",
    "    condition11 = row['ldgyr1'] > row['dth_dte']\n",
    "\n",
    "    if condition1 or condition2 or condition3 or condition4 or condition5 or condition6:\n",
    "        return 1\n",
    "    elif condition7 or condition8:\n",
    "        return 2\n",
    "    elif condition9 or condition10 or condition11:\n",
    "        return 3 \n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "# Apply the function to each row\n",
    "links1_step1['pflag'] = links1_step1.apply(check_conditions, axis=1)\n",
    "print(links1_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0efc70-3424-4ef9-981d-d91f963ba3d2",
   "metadata": {},
   "source": [
    "5. **Assigning `regfinal` Based on Regions:**\n",
    "    - If **`region1`** is equal to **`region`**, set **`regfinal`** to **`region`**.\n",
    "    - Otherwise:\n",
    "        - If either **`region1`** or **`region`** is 4 or 8, set **`regfinal`** to 8.\n",
    "        - If either **`region1`** or **`region`** is 1, set **`regfinal`** to 9.\n",
    "        - Otherwise, set **`regfinal`** to 7.\n",
    "6. **Sorting and Deduplication:**\r\n",
    "    - Sort the **`links1_step1`** dataset by the combination of **`fileno1`** and **`fileno2`**.\r\n",
    "    - Remove any duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c79a0eec-7d40-46ba-a4de-e8e076489a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   acb_no    midnme        dob sex  lst_name fst_name   snd_last    dth_dte  \\\n",
      "0     201     Smith 1980-01-01   M     Smith     John        Doe 2020-03-15   \n",
      "3     203  Williams 1987-09-15   M  Williams   Robert     Garcia 2021-08-05   \n",
      "4     205    Taylor 1980-07-14   M    Taylor  Michael      Davis 2022-01-01   \n",
      "1     206     Clark 1990-04-18   F     Clark     Anna  Rodriguez 2023-07-11   \n",
      "5     202   Johnson 1976-05-10   F   Johnson     Mary   Martinez 2018-12-20   \n",
      "\n",
      "    uli bsurn  ...  uli1  bsurn1     ldgyr1 region1 dob_year_diff  \\\n",
      "0  A123  X123  ...  G123    P123 2018-01-01       1           NaN   \n",
      "3  C789        ...  H789    R789 2019-05-15       4             5   \n",
      "4  D012  W012  ...  J345    T345 2020-01-20       8             5   \n",
      "1  E345  U345  ...  K678    U678 2021-07-01       1           NaN   \n",
      "5  B456  Y456  ...  B456    Q456 2016-12-31       2             1   \n",
      "\n",
      "         matflag  fileno1  fileno2 pflag regfinal  \n",
      "0            NaN  0000101  0000201     1        1  \n",
      "3  Partial Match  0000103  0000203     2        8  \n",
      "4  Partial Match  0000105  0000205     1        8  \n",
      "1            NaN  0000106  0000206     1        9  \n",
      "5    Close Match  0000107  0000202     1        2  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to assign regfinal\n",
    "def assign_regfinal(row):\n",
    "    if row['region'] == row['region1']:\n",
    "        return row['region']\n",
    "    elif row['region'] == 4 or row['region1'] == 4 or row['region'] == 8 or row['region1'] == 8:\n",
    "        return 8\n",
    "    elif row['region'] == 1 or row['region1'] == 1:\n",
    "        return 9\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "# Apply the function to assign regfinal\n",
    "links1_step1['regfinal'] = links1_step1.apply(assign_regfinal, axis=1)\n",
    "\n",
    "links1_step1.sort_values(by=['fileno1', 'fileno2'], inplace=True) \n",
    "links1_step1.drop_duplicates(subset=['fileno1', 'fileno2'], keep = 'first', inplace = True )\n",
    "print(links1_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0861d-6f2a-4dec-a7a5-a2efe497da4d",
   "metadata": {},
   "source": [
    "## Creating **`links1_step2`**: based on the existing **`links1_step1`** dataset.\n",
    "\n",
    "1. **Reading Data from an External File (archive):**\n",
    "    - The **`infile`** statement specifies the input file as “ARCIN” with options for padding, ignoring missing values, and setting the record length to 94 characters.\n",
    "    - The variables read from the file are:\n",
    "        - **`fileno1`** (a character variable of length 7) \n",
    "        - **`fileno2`** (a character variable of length 7)\n",
    "        - **`date_added`** (a character variable of length 9)\n",
    "    - The data is stored in a SAS dataset named “archive.”\n",
    "2. **Sorting the “archive” Dataset:**\n",
    "    - The **`proc sort`** step sorts the “archive” dataset by the variables **`fileno1`** and **`fileno2`**.\n",
    "    - The **`nodupkey`** option removes duplicate records based on the specified key variables.\n",
    "    - The resulting dataset remains named “archive” (overwriting the original dataset).\n",
    "3. **Merging Datasets “links1_step1” and “archive”:**\n",
    "    - The **`data`** step creates a new dataset named “links1_step2.”\n",
    "    - It merges the datasets “links1_step1” (in1) and “archive” (in2) based on the common variables **`fileno1`** and **`fileno2`**.\n",
    "    - Only records that exist in “links1_step1” (in1=1) and do not exist in “archive” (in2=0) are included.\n",
    "    - In other words, this step links records that were previously identified as duplicates but are now excluded.\n",
    "4. **Final Output:**\n",
    "    - The final output is the dataset “links1_step2,” any records from “archive_data” that match existing records in “links1_step1” are excluded from         the merged dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b7dca82-9f90-43c9-81fb-c03b535a543e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m archive_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_fwf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARCIN\u001b[39m\u001b[38;5;124m\"\u001b[39m, width \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m ], names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesno1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesno2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_added\u001b[39m\u001b[38;5;124m\"\u001b[39m] )\n\u001b[0;32m      2\u001b[0m archive_data\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfileno1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfileno2\u001b[39m\u001b[38;5;124m\"\u001b[39m ], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m ) \n\u001b[0;32m      3\u001b[0m links1_step2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(links1_step1, archieve_data, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfileno1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfileno2\u001b[39m\u001b[38;5;124m\"\u001b[39m], how \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "archive_data = pd.read_fwf(\"ARCIN\", width = [7, 7, 9 ], names=[\"filesno1\", \"filesno2\", \"date_added\"] )\n",
    "archive_data.drop_duplicates(subset=[\"fileno1\", \"fileno2\" ], inplace=True ) \n",
    "links1_step2 = pd.merge(links1_step1, archieve_data, on=[\"fileno1\", \"fileno2\"], how ='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23701001-4b5c-421b-b5cb-69075231ef2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1144f-1c41-4c7d-a43d-5c1aab594d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "links1_step2.sort_values( by = ['regfinal', 'sex', 'lst_name', 'fstnme1' ], inplace=True )\n",
    "\n",
    "def apply_conditions (row):\n",
    "    if row['acb_no'] in ['e285765', 'g006715', 'n410255]: \n",
    "        row['ACD_id_comment'] = '  '\n",
    "    \n",
    "    if '924' in row['ACR_id_comment1']:\n",
    "        row['ACR_id_comment1'] = '  '\n",
    "        \n",
    "    if '924' in row['ACR_id_comment']:\n",
    "        row['ACR_id_comment'] = '  '\n",
    "\n",
    "    return row\n",
    "\n",
    "links1_step2.apply(appy_conditions, axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bfdab-0a01-4195-9f48-c1df3eccc49f",
   "metadata": {},
   "source": [
    "1. **`condition1`**:\r\n",
    "    - This variable represents the result of the first condition: whether the first character of **`fstnme1`** is equal to the first character of **`fst_name`**.\r\n",
    "    - The data type of **`condition1`** is a boolean (True or False).\r\n",
    "2. **`condition2`**:\r\n",
    "    - This variable represents the result of the second condition: whether **`mid_name`** is not equal to two spaces (\" \") and the first character of **`fstnme1`** is equal to the first character of **`mid_name`**.\r\n",
    "    - Again, the data type of **`condition2`** is a boolean.\r\n",
    "3. **`condition3`**:\r\n",
    "    - This variable represents the result of the third condition: whether **`midnme1`** is not equal to two spaces (\" \") and the first character of **`fst_name`** is equal to the first character of **`midnme1`**.\r\n",
    "    - Once more, the data type of **`condition3`** is a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315b751-9406-4747-9502-40c09e7ef0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a# Condition 1: Check if the first character of fstnme1 is equal to the first character of fst_name\n",
    "condition1 = df['fstnme1'].str[0] == df['fst_name'].str[0]\n",
    "\n",
    "# Condition 2: Check if mid_name is not equal to two spaces (\"  \") and the first character of fstnme1 is equal to the first character of mid_name\n",
    "condition2 = (df['mid_name'].str.strip() != \"\") & (df['fstnme1'].str[0] == df['mid_name'].str[0])\n",
    "\n",
    "# Condition 3: Check if midnme1 is not equal to two spaces (\"  \") and the first character of fst_name is equal to the first character of midnme1\n",
    "condition3 = (df['midnme1'].str.strip() != \"\") & (df['fst_name'].str[0] == df['midnme1'].str[0])\n",
    "\n",
    "# Combine the conditions using logical OR\n",
    "result = condition1 | condition2 | condition3\n",
    "\n",
    "links1_step3 = links1_step2[result]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048fb8a-915d-48a8-842b-a02853eff72c",
   "metadata": {},
   "source": [
    "1. **open the ODS (Output Delivery System) listing file** named “FRQB” for writing.\n",
    "2. Execute the **ODS LISTING statement** to direct the output to the “FRQB” file.\n",
    "3. Execute the **PROC SORT step** on the dataset “links1_step3” to remove duplicate keys (nodupkey):\n",
    "    - Sort the data by the variable “nn”.\n",
    "    - Save the sorted data to a new dataset named “links1_step3_nodup”.\n",
    "4. Execute the **PROC FREQ step** on the dataset “links1_step3_nodup”:\n",
    "    - Set the title for the output as “FREQUENCIES OF DUPLICATES BY CLINIC.”\n",
    "    - Create frequency tables for the cross-classification of variables “regfinal” and “pflag.”\n",
    "    - Exclude percentages from the output (nopercent).\n",
    "    - Include missing values in the frequency tables (missing).\n",
    "    - Suppress column totals (nocol) and row totals (norow).\n",
    "5. **Close the ODS listing file**.\n",
    "6. Revert back to the default ODS listing behavior.\n",
    "\n",
    "**Note**: The script assumes that the dataset “links1_step3” is already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b6c5d4-304e-4e72-aecb-fbf23db8857b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb18e6a-2194-4cc4-9484-be2f0d6b727d",
   "metadata": {},
   "source": [
    "### /OUTPUT TEXT FILE THAT IS A SHORTLIST OF ALL CASES WITH **`PFLAG=0`**  (ON LISTS TO BE SENT TO CODERS) CAN USE THIS FILE TO ADD TO CASES TO ARCHIVE IF ALREADY HAS COMMENT*/\n",
    "1. **Sort the dataset** **`links1_step2`** by the variables **`ACR_id_comment`**, **`fileno1`**, and **`fileno2`**.\n",
    "2. **Remove new line characters** (0Dx) from the **`ACR_id_comment`** variable.\n",
    "3. **Remove any commas** from the **`ACR_id_comment`** variable.\n",
    "4. Check if:\n",
    "    - The first character of **`fstnme1`** matches the first character of **`fst_name`**, **or**\n",
    "    - The first character of **`fstnme1`** matches the first character of **`mid_name`**, **or**\n",
    "    - The first character of **`fst_name`** matches the first character of **`midnme1`**.\n",
    "5. If the **`pflag`** variable is equal to 0:\n",
    "    - Write the following information to an output file named **`MATBOUT`**:\n",
    "        - **`fileno1`** at position 1\n",
    "        - **`fileno2`** at position 10\n",
    "        - **`pflag`** at position 19\n",
    "        - **`ACR_id_comment`** (up to 100 characters) at position 22\n",
    "        - The value of the macro variable **`&rdate.`** at position 124.\n",
    "\n",
    "**Note**: The script assumes that the macro variable **`&rdate.`** is defined elsewhere in the SAS program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98fc57-8858-4889-ba07-defa92bbaeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5852640a-58d7-4183-a74b-efb7f1bed6b3",
   "metadata": {},
   "source": [
    "### /OUTPUT TEXT FILE THAT IS A SHORTLIST OF ALL CASES WITH **`PFLAG !=0`**  (ON LISTS TO BE SENT TO CODERS)  CAN USE THIS FILE TO ADD TO CASES TO ARCHIVE IF ALREADY HAS COMMENT*/\n",
    "\n",
    "1. **Data Preparation**:\n",
    "    - The code starts by reading data from a dataset called **`links1_step2`**.\n",
    "    - It assigns the value of the **`ACR_id_comment`** variable after removing any newline characters (represented by **`'0D'x`**) and compressing any commas in the comment.\n",
    "    - The purpose of this step is to clean up the comment data.\n",
    "2. **Conditional Check**:\n",
    "    - The code checks if certain conditions are met:\n",
    "        - If the first character of **`fstnme1`** matches the first character of **`fst_name`**.\n",
    "        - If **`mid_name`** is not equal to two spaces (i.e., it contains a non-empty value) and the first character of **`fstnme1`** matches the first character of **`mid_name`**.\n",
    "        - If **`midnme1`** is not equal to two spaces and the first character of **`fst_name`** matches the first character of **`midnme1`**.\n",
    "    - If any of these conditions are true, the code proceeds to the next step.\n",
    "3. **Filtering by PFLAG**:\n",
    "    - The code checks if the value of **`pflag`** is not equal to 0.\n",
    "    - If this condition is met, the code continues to the next step.\n",
    "4. **File Output**:\n",
    "    - The code opens an output file called **`RIDBOUT`**.\n",
    "    - It writes specific values from the dataset to the output file:\n",
    "        - **`fileno1`** at position 1.\n",
    "        - **`fileno2`** at position 10.\n",
    "        - **`pflag`** at position 19.\n",
    "        - **`ACR_id_comment`** (up to 60 characters) at position 22.\n",
    "        - The value of **`&rdate.`** (which seems to be a macro or variable) at position 124.\n",
    "    - The code repeats this process for each record in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f5e8e-592f-4e5d-984c-b8bc3d15cf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec46dfb9-2745-49c7-8af6-007136d751b4",
   "metadata": {},
   "source": [
    "### LINK2: ONE CASE IN CCR YEAR ONE CASE IN PRE-CCR\n",
    "\n",
    "- DUPLICATE BASED ON:\n",
    "    - a) sex, soundex surname and similar dob (dob same or switch of day/mon/yr)\n",
    "    - b) sex, exact surname, fst_name either fst or mid name, and same dth date and similar dob (one digit out in one of the dob fields or one dob month and day same or dob year and day same or dob year and month same)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a1780-d724-4059-8292-c5370086d7d6",
   "metadata": {},
   "source": [
    "1. **Data Preparation for maligothyr**:\n",
    "    - Create a new dataset named **`maligothyr`**.\n",
    "    - Merge two existing datasets: **`&refdata`** (with the alias **`in1`**) and **`step0`** (with the alias **`in2`**).\n",
    "    - The merge is based on the common variable **`acb_no`**.\n",
    "2. **Conditional Checks**:\n",
    "    - For each record in the merged dataset:\n",
    "        - Check if the record is only present in **`step0`** (i.e., **`in2=0`**).\n",
    "        - Check if the value of the **`dob`** (date of birth) variable is not missing (not equal to **`.`**, which represents a missing value).\n",
    "3. **Soundex Calculation**:\n",
    "    - Calculate the Soundex code for the **`lst_name`** (last name) and store it in the variable **`snd_last`**.\n",
    "    - Soundex is a phonetic algorithm that converts names or words into a code based on their pronunciation.\n",
    "4. **Resulting Dataset**:\n",
    "    - The resulting dataset **`maligothyr`** contains the merged records that meet the specified conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8e4326-6cde-4dc3-8b7a-94c8023380cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (3499967669.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    - Create a new dataset named **`maligothyr`**.\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "import jellyfish \n",
    "\n",
    "refdata = pd.read_csv('ilepathtorefdata')\n",
    "step0 = pd.read_csv('ilepathtorefdata')\n",
    "\n",
    "merged_data = pd.merge(refdata, step0, on='acb_no', how='right', indicator= True)\n",
    "\n",
    "filtered_data = merged_data['dob'].notna()\n",
    "\n",
    "filtered_data['snd_last'] = filtered_data['lst_name'].apply(jellyfish.soundex) \n",
    "\n",
    "maligothyr = filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a8cd55-7ba3-4d71-9cc9-24f5b4013336",
   "metadata": {},
   "source": [
    "### Create a new table named **`link2a`** \n",
    "\n",
    "1. **PROC SQL**: Select all columns from two existing datasets: **`maligCCR1`** and **`maligothyr`**.\n",
    "2. **Merge** is based on the following conditions:\n",
    "     - The sex in **`maligCCR1`** (**`sex1`**) must match the sex in **`maligothyr`**.\n",
    "     - The **`acbno1`** in **`maligCCR1`** must not be equal to the **`acb_no`** in **`maligothyr`**.\n",
    "5. **Soundex Calculation**:\n",
    "    - The Soundex code for the last name in **`maligCCR1`** (**`snd_last1`**) must match the Soundex code for the last name in **`maligothyr`** (**`snd_last`**).\n",
    "6. **Date of Birth Matching**:\n",
    "    - The date of birth (**`dob`**) in **`maligCCR1`** must match one of the following conditions:\n",
    "        - **`dob1`** in **`maligCCR1`** is equal to **`dob`** in **`maligothyr`**.\n",
    "        - The year of **`dob1`** minus 1900 is equal to the day of **`dob`**, and **`day(dob1)`** equals the year of **`dob`** minus 1900, and **`month(dob1)`** equals the month of **`dob`**.\n",
    "        - **`month(dob1)`** equals the year of **`dob`** minus 1900, and the year of **`dob1`** minus 1900 equals the month of **`dob`**, and **`day(dob1)`** equals the day of **`dob`**.\n",
    "        - The year of **`dob1`** equals the year of **`dob`**, and **`day(dob1)`** equals the month of **`dob`**, and **`month(dob1)`** equals the day of **`dob`**.\n",
    "7. **Resulting Dataset**:\n",
    "    - The resulting dataset **`link2a`** contains records that meet the specified conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f61d85-0f65-494f-9e26-24cb8c21482a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(maligCCR1, maligothr, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex1\u001b[39m\u001b[38;5;124m'\u001b[39m, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m      3\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabcno1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macb_no\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnd_last1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnd_last\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_data = pd.merge(maligCCR1, maligothr, left='sex1', right='sex' )\n",
    "\n",
    "filtered_data = merged_data[\n",
    "    (merged_data['acbno1'] != merged_data['acb_no']) &\n",
    "    (merged_data['snd_last1'] == merged_data['snd_last'])\n",
    "]\n",
    "\n",
    "# Function to check date of birth matching conditions\n",
    "def dob_match(row):\n",
    "    dob1 = row['dob1']\n",
    "    dob = row['dob']\n",
    "    return (\n",
    "        dob1 == dob or\n",
    "        (dob1.year - 1900 == dob.day and dob1.day == dob.year - 1900 and dob1.month == dob.month) or\n",
    "        (dob1.month == dob.year - 1900 and dob1.year - 1900 == dob.month and dob1.day == dob.day) or\n",
    "        (dob1.year == dob.year and dob1.day == dob.month and dob1.month == dob.day)\n",
    "    )\n",
    "\n",
    "\n",
    "# Apply the date of birth matching conditions\n",
    "filtered_data = filtered_data[filtered_data.apply(dob_match, axis=1)]\n",
    "\n",
    "# Resulting dataset\n",
    "link2a = filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9398ee-61ae-490f-b8df-5af67430266e",
   "metadata": {},
   "source": [
    "###     Create a new dataset named **`link2b`**.\n",
    "\n",
    "1. **Create a New Table “link2b”**:\r\n",
    "    - Use the **`proc sql`** procedure to create a new table named “link2b.”\r\n",
    "    - Join two existing tables: “maligCCR1” and “maligothyr.”\r\n",
    "    - Specify the following conditions for the join:\r\n",
    "        - Matching sex (where **`sex1`** equals **`sex`**).\r\n",
    "        - Excluding records where **`acbno1`** equals **`acb_no`**.\r\n",
    "        - Matching last names (where **`lstnme1`** equals **`lst_name`**).\r\n",
    "        - Matching first names (where **`fst_name`** matches any of the following: **`fstnme1`**, **`midnme1`**, or both).\r\n",
    "        - Matching death dates (where **`dth_dte`** equals **`dth_dte1`**).\r\n",
    "        - Limiting the difference in years between **`dob1`** and **`dob`** to be less than or equal to 10.\r\n",
    "2. **Read the Newly Created “link2b” Table**:\r\n",
    "    - Use the **`data`** step to read the newly created “linkhere **`matflag`** is 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7853ff3e-a826-415c-856f-8e5c088538c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_data2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(maligCCR2, maligothr, left\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex1\u001b[39m\u001b[38;5;124m'\u001b[39m, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m      3\u001b[0m filtered_data2 \u001b[38;5;241m=\u001b[39m merged_data2[\n\u001b[0;32m      4\u001b[0m     (merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macbno1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macb_no\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      5\u001b[0m     (merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstnme1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlst_name\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     (\u001b[38;5;28mabs\u001b[39m(merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdob\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m merged_data2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdob1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m link2b \u001b[38;5;241m=\u001b[39m filtered_data2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_data2 = pd.merge(maligCCR2, maligothr, left='sex1', right='sex' )\n",
    "\n",
    "filtered_data2 = merged_data2[\n",
    "    (merged_data2['acbno1'] == merged_data2['acb_no']) &\n",
    "    (merged_data2['lstnme1'] == merged_data2['lst_name']) &\n",
    "    (\n",
    "        (merged_data2['fst_name'] == merged_data2['fstnme1']) |\n",
    "        (merged_data2['fst_name'] == merged_data2['midnme1'])\n",
    "    ) &\n",
    "    (merged_data2['dth_dte'] == merged_data2['dth_dte']) &  # Checking if 'dth_dte' is not NaN\n",
    "    (abs(merged_data2['dob'].dt.year - merged_data2['dob1'].dt.year) <= 10)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b1e7dc-e15e-4c34-add1-591ed363ee53",
   "metadata": {},
   "source": [
    "3. **Calculate “matflag”**:\n",
    "    - Calculate the absolute differences in years, months, and days between the variables **`dob1`** and **`dob`**.\n",
    "    - Check the following conditions:\n",
    "        - If the sum of absolute differences in years, months, and days is equal to 1, set **`matflag`** to 1.\n",
    "        - Otherwise, check the following sub-conditions:\n",
    "            - If the month and day of **`dob1`** match the month and day of **`dob`**, set **`matflag`** to 2.\n",
    "            - If the year and day of **`dob1`** match the year and day of **`dob`**, set **`matflag`** to 2.\n",
    "            - If the year and month of **`dob1`** match the year and month of **`dob`**, set **`matflag`** to 2.\n",
    "            - If none of the above conditions are met, check the following:\n",
    "                - If **`dob_stat`** is ‘m’ (month status) and the absolute difference in years between **`dob1`** and **`dob`** is 1, set **`matflag`** to 3.\n",
    "                - If **`dob_stat`** is ‘d’ (day status) and the sum of absolute differences in years and months between **`dob1`** and **`dob`** is 1, set **`matflag`** to 3.\n",
    "                - Otherwise, set **`matflag`** to 9.\n",
    "        - Exclude records where **`matflag`** is 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1264bb-874e-44f7-817a-52f489f96928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute differences in years, months, and days between dob1 and dob\n",
    "filtered_data2['year_diff'] = abs(filtered_data2['dob1'].dt.year - filtered_data2['dob'].dt.year)\n",
    "filtered_data2['month_diff'] = abs(filtered_data2['dob1'].dt.month - filtered_data2['dob'].dt.month)\n",
    "filtered_data2['day_diff'] = abs(filtered_data2['dob1'].dt.day - filtered_data2['dob'].dt.day)\n",
    "\n",
    "# Function to calculate matflag\n",
    "def calculate_matflag(row):\n",
    "    total_diff = row['year_diff'] + row['month_diff'] + row['day_diff']\n",
    "    \n",
    "    if total_diff == 1:\n",
    "        return 1\n",
    "    \n",
    "    if (\n",
    "        (row['dob1'].month == row['dob'].month and row['dob1'].day == row['dob'].day) or\n",
    "        (row['dob1'].year == row['dob'].year and row['dob1'].day == row['dob'].day) or\n",
    "        (row['dob1'].year == row['dob'].year and row['dob1'].month == row['dob'].month)\n",
    "    ):\n",
    "        return 2\n",
    "    \n",
    "    if row['dob_stat'] == 'm' and row['year_diff'] == 1:\n",
    "        return 3\n",
    "    \n",
    "    if row['dob_stat'] == 'd' and (row['year_diff'] + row['month_diff'] == 1):\n",
    "        return 3\n",
    "    \n",
    "    return 9\n",
    "\n",
    "# Apply the function to calculate matflag\n",
    "filtered_data2['matflag'] = filtered_data2.apply(calculate_matflag, axis=1)\n",
    "\n",
    "filtered_data2 = filtered_data2.drop(columns=['year_diff', 'month_diff', 'day_diff'])\n",
    "\n",
    "# Exclude records where matflag is not set as required\n",
    "filtered_data2 = filtered_data2[filtered_data2['matflag'] != 9]\n",
    "\n",
    "# Resulting dataset\n",
    "link2b = filtered_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1d3b3-f1c8-416b-b5ed-ff575fc83ff7",
   "metadata": {},
   "source": [
    "### Sorting and Depulication: \n",
    "- The code mergers **`Links2a`** and **`Links2b`** into **`Links2`** sorting **`Links2`** by **`acb_no`** and **`acb_no1`** and removes any duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2bcaf-1a69-42a6-be4c-1961835f5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the Links (Links1)\n",
    "Links2= pd.concat([link2a, link2b.astype(link1a.dtypes)], ignore_index=True)\n",
    "# Sorting and Deduplication\n",
    "Links2.sort_values(by=['acb_no', 'acbno1'], inplace=True)\n",
    "\n",
    "# Drop rows where matflag is 'Exact Match'\n",
    "Links2.drop_duplicates(subset=['acb_no', 'acbno1'], keep='first', +)\n",
    "print(Links12) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91daeea4-c946-4423-8214-307af308857f",
   "metadata": {},
   "source": [
    "### Assign step 1 Conditions on Links2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f77753-20c6-4e29-8d3f-cb2a5d9d7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize fileno1 and fileno2 columns\n",
    "fileno1 = []\n",
    "fileno2 = []\n",
    "\n",
    "# Determine fileno1 and fileno2 based on acb_no and acbno\n",
    "for index, row in Links1.iterrows():\n",
    "    if row['acb_no'] > row['acbno1']:\n",
    "        fileno1.append(str(row['acbno1']).zfill(7))\n",
    "        fileno2.append(str(row['acb_no']).zfill(7))\n",
    "    else:\n",
    "        fileno1.append(str(row['acb_no']).zfill(7))\n",
    "        fileno2.append(str(row['acbno1']).zfill(7))\n",
    "\n",
    "# Add fileno1 and fileno2 to the DataFrame\n",
    "Links1['fileno1'] = fileno1\n",
    "Links1['fileno2'] = fileno2\n",
    "\n",
    "# Create links1_step1 DataFrame\n",
    "links2_step1 = Links2.copy()\n",
    "\n",
    "print(links2_step1)\n",
    "\n",
    "links2_step1['pflag'] = links2_step1.apply(check_conditions, axis=1)\n",
    "links2_step1.drop_duplicates(subset=['fileno1', 'fileno2'], keep = 'first', inplace = True )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b02eb-b9aa-4090-bb21-4edfdbee3fb8",
   "metadata": {},
   "source": [
    "\n",
    "1. **Create a New Dataset “links2_step2”**:\n",
    "    - Use the **`data`** step to create a new dataset named “links2_step2.”\n",
    "    - Merge two existing datasets: “links2_step1” and “archive.”\n",
    "    - Specify the variables “fileno1” and “fileno2” as the merge keys.\n",
    "    - The resulting dataset will contain records from both datasets.\n",
    "2. **Check for Exclusion**:\n",
    "    - For each observation in the merged dataset:\n",
    "        - Check if the observation is from the “archive” dataset (in2=1) or not (in2=0).\n",
    "        - If the observation is not from the “archive” dataset (in2=0), keep it in the output dataset.\n",
    "        - Exclude observations that are from the “archive” dataset (in2=1).\n",
    "3. The resulting dataset “links2_step2” will contain only the records that were not previously identified as duplicates in the “archive” dataset.\n",
    "\n",
    "Please note that the code assumes the existence of the datasets “links2_step1” and “archive” in the SAS session. Adjustments may be needed if any assumptions are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781790d-d3b1-47f1-830f-028d853b545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = pd.read_csv('archive.csv')\n",
    "\n",
    "# Merge the datasets on 'fileno1' and 'fileno2'\n",
    "filtered_dataset = pd.merge(links2_step1, archive, on=['fileno1', 'fileno2'], how='outer', indicator='in2')\n",
    "\n",
    "# Check for exclusion: keep only records not in the archive dataset\n",
    "# `in2` column created by `pd.merge` contains 'both', 'left_only', or 'right_only'\n",
    "# We only want rows with 'left_only' (rows from links2_step1 but not in archive)\n",
    "links2_step2 = filtered_dataset[filtered_dataset['in2'] == 'left_only']\n",
    "\n",
    "# Drop the `in2` indicator column as it is no longer needed\n",
    "links2_step2 = filtered_dataset.drop(columns=['in2'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcaba5-b028-48a8-978c-bfa2c7f72a33",
   "metadata": {},
   "source": [
    "### Assigning regfinal on Links2 Based on Regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74d12e-0810-4c87-9b6b-253a68f72339",
   "metadata": {},
   "outputs": [],
   "source": [
    "links2_step2.sort_values( by = ['regfinal', 'sex', 'lst_name', 'fstnme1' ], inplace=True )\n",
    "\n",
    "def apply_conditions (row):\n",
    "    if row['acb_no'] in ['e285765', 'g006715', 'n410255]: \n",
    "        row['ACD_id_comment'] = '  '\n",
    "    \n",
    "    if '924' in row['ACR_id_comment1']:\n",
    "        row['ACR_id_comment1'] = '  '\n",
    "        \n",
    "    if '924' in row['ACR_id_comment']:\n",
    "        row['ACR_id_comment'] = '  '\n",
    "\n",
    "    return row\n",
    "\n",
    "links2_step2.apply(appy_conditions, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7904c3d-cf3b-4c7e-818f-54985fc9db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "a# Condition 1: Check if the first character of fstnme1 is equal to the first character of fst_name\n",
    "condition1 = df['fstnme1'].str[0] == df['fst_name'].str[0]\n",
    "\n",
    "# Condition 2: Check if mid_name is not equal to two spaces (\"  \") and the first character of fstnme1 is equal to the first character of mid_name\n",
    "condition2 = (df['mid_name'].str.strip() != \"\") & (df['fstnme1'].str[0] == df['mid_name'].str[0])\n",
    "\n",
    "# Condition 3: Check if midnme1 is not equal to two spaces (\"  \") and the first character of fst_name is equal to the first character of midnme1\n",
    "condition3 = (df['midnme1'].str.strip() != \"\") & (df['fst_name'].str[0] == df['midnme1'].str[0])\n",
    "\n",
    "# Combine the conditions using logical OR\n",
    "result = condition1 | condition2 | condition3\n",
    "\n",
    "links2_step3 = links2_step2[result]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317765c3-9be0-429e-b737-66bcc17c70d3",
   "metadata": {},
   "source": [
    "### Sorting : \n",
    "-  removes any duplicate records by **`fileno1`** and **`fileno2`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7388441-f023-4f1d-8e1c-a15eafc27a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62dd91ad-2d8f-45c7-b652-0c9b676e910b",
   "metadata": {},
   "source": [
    "### /**OUTPUT TEXT FILE THAT IS A SHORTLIST OF ALL CASES WITH PFLAG=0 (ON LISTS TO BE SENT TO CODERS)  CAN USE THIS FILE TO ADD TO CASES TO ARCHIVE IF ALREADY HAS COMMENT*** \n",
    "\n",
    "1. **Sort the Dataset “links2_step2”**:\r\n",
    "    - Use the **`proc sort`** procedure to sort the dataset “links2_step2” by the variables “fileno1” and “fileno2.”\r\n",
    "    - This ensures that the data is ordered for subsequent processing.\r\n",
    "2. **Clean the “ACR_id_comment” Variable**:\r\n",
    "    - Remove new lines and extra spaces from the “ACR_id_comment” variable:\r\n",
    "        - Use the **`translate`** function to replace newline characters (0D’x) with spaces.\r\n",
    "        - Use the **`compress`** function to remove any extra commas from the comment.\r\n",
    "        - The cleaned “ACR_id_comment” will be used in the output.\r\n",
    "3. **Check Conditions for Inclusion**:\r\n",
    "    - For each observation in the dataset:\r\n",
    "        - Check if the first character of “fstnme1” matches the first character of “fst_name.” If true, keep the observation.\r\n",
    "        - If “mid_name” is not empty and the first character of “fstnme1” matches the first character of “mid_name,” keep the observation.\r\n",
    "        - If “midnme1” is not empty and the first character of “fst_name” matches the first character of “midnme1,” keep the observation.\r\n",
    "        - Additionally, keep observations where “pflag” is 0 (i.e., pflag=0).\r\n",
    "4. **Write Selected Observations to a Text File**:\r\n",
    "    - Use the **`file`** statement to specify the output file (“MATOOUT”).\r\n",
    "    - Use the **`put`** statement to write the formatted output:\r\n",
    "        - The “fileno1” value is printed at position 1.\r\n",
    "        - The “fileno2” value is printed at position 10.\r\n",
    "        - The “pflag” value is printed at position 19.\r\n",
    "        - The cleaned “ACR_id_comment” (up to 100 characters) is printed at position 22.\r\n",
    "        - The current date (“&rdate.”) is printed at position 124./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b720bac-7c5f-434e-b8f4-5449a0640c87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'links2_step2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Clean the 'ACR_id_comment' variable\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#replace newlice characters )D'xs with spaces\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m links2_step2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACR_id_comment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m links2_step2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACR_id_comment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#remove comment\u001b[39;00m\n\u001b[0;32m      7\u001b[0m links2_step2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACR_id_comment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m links2_step2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACR_id_comment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'links2_step2' is not defined"
     ]
    }
   ],
   "source": [
    "# Clean the 'ACR_id_comment' variable\n",
    "\n",
    "#replace newlice characters )D'xs with spaces\n",
    "links2_step2['ACR_id_comment'] = links2_step2['ACR_id_comment'].str.replace('\\n', ' ').str.replace('\\r', ' ')\n",
    "\n",
    "#remove comment\n",
    "links2_step2['ACR_id_comment'] = links2_step2['ACR_id_comment'].str.replace(',', '')\n",
    "\n",
    "conditions_plag0 = (\n",
    "    (links2_step2['fstnme1'] == links2_step2['fstnme1']) |\n",
    "    (links2_step2['mid_name'].notna & links2_step2['fstnme1'] == links2_step2['mid_name']) |  \n",
    "    (links2_step2['midnme1'].notna & links2_step2['fst_name'] == links2_step2['midnme1']) |\n",
    "    (links2_step2['pflag'] == 0)\n",
    "    \n",
    ")\n",
    "\n",
    "selected_observations = links2_step2[conditions_plag0]\n",
    "current_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "with open('MATOOUT.txt', 'w') as f:\n",
    "    for _, row in selected_observations.iterrows():\n",
    "        fileno1 = str(row['fileno1']).ljust(9)[:9]\n",
    "        fileno2 = str(row['fileno2']).ljust(9)[:9]\n",
    "        pflag = str(row['pflag']).ljust(3)[:3]\n",
    "        ACR_id_comment = str(row['ACR_id_comment']).ljust(100)[:100]\n",
    "        \n",
    "        f.write(f\"{fileno1: <9}{fileno2: <9}{pflag: <3}{ACR_id_comment: <100}{current_date}\\n\")\n",
    "\n",
    "print(\"Text file 'MATOOUT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591eac2-66be-4633-9ca0-63a9f2cab88b",
   "metadata": {},
   "source": [
    "### OUTPUT TEXT FILE THAT IS A SHORTLIST OF ALL CASES WITH PFLAG NOT=0 (REJECTED CASES NOT TO BE SENT TO CODERS) CAN USE THIS FILE TO ADD TO CASES TO ARCHIVE IF ALREADY HAS COMMENT***/\n",
    "\n",
    "1. **Clean the “ACR_id_comment” Variable**:\n",
    "    - Remove new lines and extra spaces from the “ACR_id_comment” variable:\n",
    "        - Use the **`translate`** function to replace newline characters (0D’x) with spaces.\n",
    "        - Use the **`compress`** function to remove any extra commas from the comment.\n",
    "        - The cleaned “ACR_id_comment” will be used in the output.\n",
    "2. **Check Conditions for Inclusion**:\n",
    "    - For each observation in the dataset:\n",
    "        - Check if the first character of “fstnme1” matches the first character of “fst_name.” If true, keep the observation.\n",
    "        - If “mid_name” is not empty and the first character of “fstnme1” matches the first character of “mid_name,” keep the observation.\n",
    "        - If “midnme1” is not empty and the first character of “fst_name” matches the first character of “midnme1,” keep the observation.\n",
    "        - Additionally, keep observations where “pflag” is not equal to 0 (i.e., pflag not in (0)).\n",
    "3. **Write Selected Observations to a Text File**:\n",
    "    - Use the **`file`** statement to specify the output file (“RIDOOUT”).\n",
    "    - Use the **`put`** statement to write the formatted output:\n",
    "        - The “fileno1” value is printed at position 1.\n",
    "        - The “fileno2” value is printed at position 10.\n",
    "        - The “pflag” value is printed at position 19.\n",
    "        - The cleaned “ACR_id_comment” (up to 100 characters) is printed at position 22.\n",
    "        - The current date (“&rdate.”) is printed at position 124.\n",
    "4. **Clean up Temporary Datasets**:\n",
    "    - Use the **`proc datasets`** procedure to delete temporary datasets in the “work” library.\n",
    "    - The **`memtype=data`** option ensures that only data-type datasets are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915c73a-bbc5-40a8-a27a-712e38b066b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check conditions for inclusion\n",
    "conditions_plagnot0 = (\n",
    "    (links2_step2['fstnme1'].str[0] == links2_step2['fst_name'].str[0]) |\n",
    "    (links2_step2['mid_name'].notna() & (links2_step2['fstnme1'].str[0] == links2_step2['mid_name'].str[0])) |\n",
    "    (links2_step2['midnme1'].notna() & (links2_step2['fst_name'].str[0] == links2_step2['midnme1'].str[0])) |\n",
    "    (links2_step2['pflag'] != 0)\n",
    ")\n",
    "\n",
    "selected_observations = links2_step2[conditions_plagnot0]\n",
    "\n",
    "with open('RIDOOUT.txt', 'w') as f:\n",
    "    for _, row in selected_observations.iterrows():\n",
    "        fileno1 = str(row['fileno1']).ljust(9)[:9]\n",
    "        fileno2 = str(row['fileno2']).ljust(9)[:9]\n",
    "        pflag = str(row['pflag']).ljust(3)[:3]\n",
    "        ACR_id_comment = str(row['ACR_id_comment']).ljust(100)[:100]\n",
    "        \n",
    "        f.write(f\"{fileno1: <9}{fileno2: <9}{pflag: <3}{ACR_id_comment: <100}{current_date}\\n\")\n",
    "\n",
    "print(\"Text file 'RIDOOUT.txt' created successfully.\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
